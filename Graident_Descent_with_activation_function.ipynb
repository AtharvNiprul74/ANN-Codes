{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPS3+G7bSToZ/8FF4tDES2c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AtharvNiprul74/ANN-Codes/blob/main/Graident_Descent_with_activation_function.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.Student Score Prediction.**"
      ],
      "metadata": {
        "id": "1sr0UPXfbZC8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ay4y1NhuBTBr",
        "outputId": "5b89d968-159d-4bfd-df50-4ea9c5f80ead"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for sigmoid:\n",
            "Weight=-0.9839285093947203,Bias=-0.5634634661028011\n",
            "Normalized value= 1.610887798481921\n",
            "Output for sigmoid= 0.10447504057476407\n",
            "\n",
            "\n",
            "Training for relu:\n",
            "Weight=-0.5832349451778038,Bias=-0.6016720619786936\n",
            "Normalized value= 1.610887798481921\n",
            "-1.54119811881389\n",
            "Output for Relu= 0.0\n",
            "\n",
            "\n",
            "Training for tanh:\n",
            "Weight=-0.1444431927824405,Bias=-0.44960184872287506\n",
            "Normalized value= 1.610887798481921\n",
            "Output= -0.5930019861004836\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1/(1+np.exp(-x))\n",
        "\n",
        "def relu(x):\n",
        "  return np.maximum(0,x)\n",
        "\n",
        "def tanh(x):\n",
        "  return np.tanh(x)\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "# generating data set randomly\n",
        "study_hours=np.linspace(0,10,100)\n",
        "# print(study_hours)\n",
        "score=5*study_hours + np.random.normal(0,2,100)\n",
        "# print(score)\n",
        "\n",
        "# normalizing data set\n",
        "norm_study_hours=(study_hours-np.mean(study_hours))/np.std(study_hours)\n",
        "# print(norm_study_hours)\n",
        "norm_score=(score-np.mean(score))/np.std(score)\n",
        "# print(norm_score)\n",
        "\n",
        "# gradient descent\n",
        "w=np.random.randn()\n",
        "b=np.random.randn()\n",
        "learning_rate=0.0001\n",
        "\n",
        "def graident(act_fun,itrs=1750):\n",
        "  global w,b\n",
        "  for i in range(itrs):\n",
        "    norm_score_pred=act_fun((w*norm_study_hours)+b)\n",
        "    error=(norm_score-norm_score_pred)\n",
        "\n",
        "    dw=-(2/len(norm_study_hours))*np.sum(norm_study_hours*error)\n",
        "    db=-(2/len(norm_study_hours))*np.sum(error)\n",
        "\n",
        "    w=w-learning_rate*dw\n",
        "    b=b-learning_rate*db\n",
        "\n",
        "  return w,b\n",
        "\n",
        "# sigmoid.\n",
        "w_sigmoid,b_sigmoid=graident(sigmoid)\n",
        "print(\"Training for sigmoid:\")\n",
        "print(f\"Weight={w_sigmoid},Bias={b_sigmoid}\")\n",
        "\n",
        "new_hour= 9.6969697\n",
        "normalized=(new_hour-np.mean(study_hours))/np.std(study_hours)\n",
        "print(\"Normalized value=\",normalized)\n",
        "print(\"Output for sigmoid=\",sigmoid((w_sigmoid*normalized)+b_sigmoid))\n",
        "print(\"\\n\")\n",
        "\n",
        "# relu.\n",
        "w_relu,b_relu=graident(relu)\n",
        "print(\"Training for relu:\")\n",
        "print(f\"Weight={w_relu},Bias={b_relu}\")\n",
        "\n",
        "new_hour= 9.6969697\n",
        "normalized=(new_hour-np.mean(study_hours))/np.std(study_hours)\n",
        "print(\"Normalized value=\",normalized)\n",
        "print((w_relu*normalized)+b_relu)\n",
        "print(\"Output for Relu=\",relu((w_relu*normalized)+b_relu))\n",
        "print(\"\\n\")\n",
        "\n",
        "# tanh\n",
        "w_tanh,b_tanh=graident(tanh)\n",
        "print(\"Training for tanh:\")\n",
        "print(f\"Weight={w_tanh},Bias={b_tanh}\")\n",
        "\n",
        "new_hour= 9.6969697\n",
        "normalized=(new_hour-np.mean(study_hours))/np.std(study_hours)\n",
        "print(\"Normalized value=\",normalized)\n",
        "print(\"Output=\",tanh((w_tanh*normalized)+b_tanh))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1/(1+np.exp(-x))\n",
        "\n",
        "def relu(x):\n",
        "  return np.maximum(0,x)\n",
        "\n",
        "def tanh(x):\n",
        "  return np.tanh(x)\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "# generating data set randomly\n",
        "study_hours=np.linspace(0,10,100)\n",
        "# print(study_hours)\n",
        "score=5*study_hours + np.random.normal(0,2,100)\n",
        "# print(score)\n",
        "\n",
        "# normalizing data set\n",
        "norm_study_hours=(study_hours-np.mean(study_hours))/np.std(study_hours)\n",
        "# print(norm_study_hours)\n",
        "norm_score=(score-np.mean(score))/np.std(score)\n",
        "print(norm_score)\n",
        "\n",
        "# gradient descent\n",
        "w=np.random.randn()\n",
        "b=np.random.randn()\n",
        "learning_rate=0.001\n",
        "\n",
        "def graident(act_fun,itrs=1750):\n",
        "  global w,b\n",
        "  for i in range(itrs):\n",
        "    norm_score_pred=act_fun((w*norm_study_hours)+b)\n",
        "    error=(norm_score-norm_score_pred)\n",
        "\n",
        "\n",
        "    dw=-(2/len(norm_study_hours))*np.sum(norm_study_hours*error)\n",
        "    db=-(2/len(norm_study_hours))*np.sum(error)\n",
        "\n",
        "    w=w-learning_rate*dw\n",
        "    b=b-learning_rate*db\n",
        "\n",
        "    # if(i%100==0):\n",
        "    #     print(np.mean(error))\n",
        "\n",
        "  return w,b\n",
        "\n",
        "# sigmoid.\n",
        "w_sigmoid,b_sigmoid=graident(sigmoid)\n",
        "print(\"Training for sigmoid:\")\n",
        "print(f\"Weight={w_sigmoid},Bias={b_sigmoid}\")\n",
        "\n",
        "new_hour= 9.6969697\n",
        "normalized=(new_hour-np.mean(study_hours))/np.std(study_hours)\n",
        "print(\"Normalized value=\",normalized)\n",
        "print(\"Output for sigmoid=\",sigmoid((w_sigmoid*normalized)+b_sigmoid))\n",
        "print(\"\\n\")\n",
        "\n",
        "# relu.\n",
        "w_relu,b_relu=graident(relu)\n",
        "print(\"Training for relu:\")\n",
        "print(f\"Weight={w_relu},Bias={b_relu}\")\n",
        "\n",
        "new_hour= 0.1010101\n",
        "normalized=(new_hour-np.mean(study_hours))/np.std(study_hours)\n",
        "print(\"Normalized value=\",normalized)\n",
        "print((w_relu*normalized)+b_relu)\n",
        "print(\"Output for Relu=\",relu((w_relu*normalized)+b_relu))\n",
        "print(\"\\n\")\n",
        "\n",
        "# tanh\n",
        "w_tanh,b_tanh=graident(tanh)\n",
        "print(\"Training for tanh:\")\n",
        "print(f\"Weight={w_tanh},Bias={b_tanh}\")\n",
        "\n",
        "new_hour= 9.6969697\n",
        "normalized=(new_hour-np.mean(study_hours))/np.std(study_hours)\n",
        "print(\"Normalized value=\",normalized)\n",
        "print(\"Output=\",tanh((w_tanh*normalized)+b_tanh))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kSWZexzBw4_",
        "outputId": "9ce1be39-0526-4d34-98cd-f51c5e60c54a"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-1.61129629 -1.66308406 -1.52246433 -1.36974056 -1.57348544 -1.53928892\n",
            " -1.25954996 -1.33527807 -1.46857292 -1.29733962 -1.39936419 -1.36548296\n",
            " -1.23546049 -1.49310635 -1.433406   -1.24178059 -1.26859415 -1.05470091\n",
            " -1.18601368 -1.2201036  -0.7962074  -0.991048   -0.9171375  -1.0850115\n",
            " -0.93160741 -0.80867859 -0.94535964 -0.7044369  -0.8024478  -0.72641944\n",
            " -0.73420381 -0.36771683 -0.58616611 -0.69336819 -0.40456952 -0.6470693\n",
            " -0.41927916 -0.67872477 -0.55902157 -0.31832149 -0.21078872 -0.25338487\n",
            " -0.25805532 -0.24897343 -0.37421267 -0.23728625 -0.16799309  0.07172036\n",
            "  0.0092995  -0.24176761  0.07504297  0.01320948  0.00788593  0.21656859\n",
            "  0.30754321  0.32823456  0.12268678  0.22864878  0.34956954  0.47100566\n",
            "  0.30821724  0.38215627  0.29168236  0.3137072   0.61990281  0.72772114\n",
            "  0.5685169   0.74834987  0.69562528  0.59349536  0.76398133  0.95750391\n",
            "  0.77858237  1.02949536  0.49708397  0.9973098   0.93199775  0.91391664\n",
            "  1.00102463  0.75365808  1.02724231  1.13953867  1.32549735  1.08939218\n",
            "  1.0842875   1.16001682  1.38610784  1.34086406  1.25880783  1.43423791\n",
            "  1.41207617  1.56428892  1.37225495  1.45714532  1.48261302  1.37172874\n",
            "  1.64419424  1.67364041  1.67317777  1.67491435]\n",
            "Training for sigmoid:\n",
            "Weight=1.8724884512049986,Bias=-1.499784150555288\n",
            "Normalized value= 1.610887798481921\n",
            "Output for sigmoid= 0.8200350020002536\n",
            "\n",
            "\n",
            "Training for relu:\n",
            "Weight=3.4974189889442733,Bias=-2.812578394993389\n",
            "Normalized value= -1.6801732944532655\n",
            "-8.688848379731297\n",
            "Output for Relu= 0.0\n",
            "\n",
            "\n",
            "Training for tanh:\n",
            "Weight=4.323194933954555,Bias=-1.6832905259459852\n",
            "Normalized value= 1.610887798481921\n",
            "Output= 0.9999482280257627\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5B7JEL9uZKMA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}